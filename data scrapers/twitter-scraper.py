"""
sÃ¼rdÃ¼rÃ¼lebilir ÅŸehirler hackathonu

orbit

tuÄŸrap efe dikpÄ±nar
ahmet mert tezcan

tweet scraper :p
"""


#zaman aralÄ±klarÄ± bir algortimaya oturtullmalÄ±


import time
import json
import random
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.common.exceptions import TimeoutException, NoSuchElementException
from fake_useragent import UserAgent
import re
import os
from dotenv import load_dotenv


# Official 81 cities of Turkey
SEHIRLER = [
    'Adana','AdÄ±yaman','Afyonkarahisar','AÄŸrÄ±','Amasya','Ankara','Antalya','Artvin','AydÄ±n','BalÄ±kesir',
    'Bilecik','BingÃ¶l','Bitlis','Bolu','Burdur','Bursa','Ã‡anakkale','Ã‡ankÄ±rÄ±','Ã‡orum','Denizli',
    'DiyarbakÄ±r','Edirne','ElazÄ±ÄŸ','Erzincan','Erzurum','EskiÅŸehir','Gaziantep','Giresun','GÃ¼mÃ¼ÅŸhane','Hakkari',
    'Hatay','Isparta','Mersin','Ä°stanbul','Ä°zmir','Kars','Kastamonu','Kayseri','KÄ±rklareli','KÄ±rÅŸehir',
    'Kocaeli','Konya','KÃ¼tahya','Malatya','Manisa','KahramanmaraÅŸ','Mardin','MuÄŸla','MuÅŸ','NevÅŸehir',
    'NiÄŸde','Ordu','Rize','Sakarya','Samsun','Siirt','Sinop','Sivas','TekirdaÄŸ','Tokat',
    'Trabzon','Tunceli','ÅanlÄ±urfa','UÅŸak','Van','Yozgat','Zonguldak','Aksaray','Bayburt','Karaman',
    'KÄ±rÄ±kkale','Batman','ÅÄ±rnak','BartÄ±n','Ardahan','IÄŸdÄ±r','Yalova','KarabÃ¼k','Kilis','Osmaniye',
    'DÃ¼zce'
]

# Major districts mapped to their parent cities
DISTRICT_TO_CITY = {
    # Ä°stanbul districts
    'Adalar': 'Ä°stanbul', 'ArnavutkÃ¶y': 'Ä°stanbul', 'AtaÅŸehir': 'Ä°stanbul', 'AvcÄ±lar': 'Ä°stanbul',
    'BaÄŸcÄ±lar': 'Ä°stanbul', 'BahÃ§elievler': 'Ä°stanbul', 'BakÄ±rkÃ¶y': 'Ä°stanbul', 'BaÅŸakÅŸehir': 'Ä°stanbul',
    'BayrampaÅŸa': 'Ä°stanbul', 'BeÅŸiktaÅŸ': 'Ä°stanbul', 'Beykoz': 'Ä°stanbul', 'BeylikdÃ¼zÃ¼': 'Ä°stanbul',
    'BeyoÄŸlu': 'Ä°stanbul', 'BÃ¼yÃ¼kÃ§ekmece': 'Ä°stanbul', 'Ã‡atalca': 'Ä°stanbul', 'Ã‡ekmekÃ¶y': 'Ä°stanbul',
    'Esenler': 'Ä°stanbul', 'Esenyurt': 'Ä°stanbul', 'EyÃ¼psultan': 'Ä°stanbul', 'Fatih': 'Ä°stanbul',
    'GaziosmanpaÅŸa': 'Ä°stanbul', 'GÃ¼ngÃ¶ren': 'Ä°stanbul', 'KadÄ±kÃ¶y': 'Ä°stanbul', 'KaÄŸÄ±thane': 'Ä°stanbul',
    'Kartal': 'Ä°stanbul', 'KÃ¼Ã§Ã¼kÃ§ekmece': 'Ä°stanbul', 'Maltepe': 'Ä°stanbul', 'Pendik': 'Ä°stanbul',
    'Sancaktepe': 'Ä°stanbul', 'SarÄ±yer': 'Ä°stanbul', 'Silivri': 'Ä°stanbul', 'Sultanbeyli': 'Ä°stanbul',
    'Sultangazi': 'Ä°stanbul', 'Åile': 'Ä°stanbul', 'ÅiÅŸli': 'Ä°stanbul', 'Tuzla': 'Ä°stanbul',
    'Ãœmraniye': 'Ä°stanbul', 'ÃœskÃ¼dar': 'Ä°stanbul', 'Zeytinburnu': 'Ä°stanbul',
    
    # Ankara districts
    'Akyurt': 'Ankara', 'AltÄ±ndaÄŸ': 'Ankara', 'AyaÅŸ': 'Ankara', 'Bala': 'Ankara', 'BeypazarÄ±': 'Ankara',
    'Ã‡amlÄ±dere': 'Ankara', 'Ã‡ankaya': 'Ankara', 'Ã‡ubuk': 'Ankara', 'ElmadaÄŸ': 'Ankara', 'Etimesgut': 'Ankara',
    'Evren': 'Ankara', 'GÃ¶lbaÅŸÄ±': 'Ankara', 'GÃ¼dÃ¼l': 'Ankara', 'Haymana': 'Ankara', 'Kalecik': 'Ankara',
    'Kazan': 'Ankara', 'KeÃ§iÃ¶ren': 'Ankara', 'KÄ±zÄ±lcahamam': 'Ankara', 'Mamak': 'Ankara', 'NallÄ±han': 'Ankara',
    'PolatlÄ±': 'Ankara', 'Pursaklar': 'Ankara', 'Sincan': 'Ankara', 'ÅereflikoÃ§hisar': 'Ankara', 'Yenimahalle': 'Ankara',
    
    # Ä°zmir districts
    'AliaÄŸa': 'Ä°zmir', 'BalÃ§ova': 'Ä°zmir', 'BayÄ±ndÄ±r': 'Ä°zmir', 'BayraklÄ±': 'Ä°zmir', 'Bergama': 'Ä°zmir',
    'BeydaÄŸ': 'Ä°zmir', 'Bornova': 'Ä°zmir', 'Buca': 'Ä°zmir', 'Ã‡eÅŸme': 'Ä°zmir', 'Ã‡iÄŸli': 'Ä°zmir',
    'Dikili': 'Ä°zmir', 'FoÃ§a': 'Ä°zmir', 'Gaziemir': 'Ä°zmir', 'GÃ¼zelbahÃ§e': 'Ä°zmir', 'KarabaÄŸlar': 'Ä°zmir',
    'Karaburun': 'Ä°zmir', 'KarÅŸÄ±yaka': 'Ä°zmir', 'KemalpaÅŸa': 'Ä°zmir', 'KÄ±nÄ±k': 'Ä°zmir', 'Kiraz': 'Ä°zmir',
    'Konak': 'Ä°zmir', 'Menderes': 'Ä°zmir', 'Menemen': 'Ä°zmir', 'NarlÄ±dere': 'Ä°zmir', 'Ã–demiÅŸ': 'Ä°zmir',
    'Seferihisar': 'Ä°zmir', 'SelÃ§uk': 'Ä°zmir', 'Tire': 'Ä°zmir', 'TorbalÄ±': 'Ä°zmir', 'Urla': 'Ä°zmir',
    
    # Bursa districts
    'BÃ¼yÃ¼korhan': 'Bursa', 'Gemlik': 'Bursa', 'GÃ¼rsu': 'Bursa', 'HarmancÄ±k': 'Bursa', 'Ä°negÃ¶l': 'Bursa',
    'Ä°znik': 'Bursa', 'Karacabey': 'Bursa', 'Keles': 'Bursa', 'Kestel': 'Bursa', 'Mudanya': 'Bursa',
    'MustafakemalpaÅŸa': 'Bursa', 'NilÃ¼fer': 'Bursa', 'Orhaneli': 'Bursa', 'Orhangazi': 'Bursa', 'Osmangazi': 'Bursa',
    'YeniÅŸehir': 'Bursa', 'YÄ±ldÄ±rÄ±m': 'Bursa',
    
    # Antalya districts
    'Akseki': 'Antalya', 'Aksu': 'Antalya', 'Alanya': 'Antalya', 'Demre': 'Antalya', 'DÃ¶ÅŸemealtÄ±': 'Antalya',
    'ElmalÄ±': 'Antalya', 'Finike': 'Antalya', 'GazipaÅŸa': 'Antalya', 'GÃ¼ndoÄŸmuÅŸ': 'Antalya', 'Ä°bradÄ±': 'Antalya',
    'KaÅŸ': 'Antalya', 'Kemer': 'Antalya', 'Kepez': 'Antalya', 'KonyaaltÄ±': 'Antalya', 'Korkuteli': 'Antalya',
    'Kumluca': 'Antalya', 'Manavgat': 'Antalya', 'MuratpaÅŸa': 'Antalya', 'Serik': 'Antalya',
    
    # Konya districts
    'AhÄ±rlÄ±': 'Konya', 'AkÃ¶ren': 'Konya', 'AkÅŸehir': 'Konya', 'AltÄ±nekin': 'Konya', 'BeyÅŸehir': 'Konya',
    'BozkÄ±r': 'Konya', 'Cihanbeyli': 'Konya', 'Ã‡eltik': 'Konya', 'Ã‡umra': 'Konya', 'Derbent': 'Konya',
    'Derebucak': 'Konya', 'DoÄŸanhisar': 'Konya', 'Emirgazi': 'Konya', 'EreÄŸli': 'Konya', 'Ermenek': 'Konya',
    'GÃ¼neysinir': 'Konya', 'Hadim': 'Konya', 'HalkapÄ±nar': 'Konya', 'HÃ¼yÃ¼k': 'Konya', 'IlgÄ±n': 'Konya',
    'KadÄ±nhanÄ±': 'Konya', 'KarapÄ±nar': 'Konya', 'Karatay': 'Konya', 'Kulu': 'Konya', 'Meram': 'Konya',
    'SarayÃ¶nÃ¼': 'Konya', 'SelÃ§uklu': 'Konya', 'SeydiÅŸehir': 'Konya', 'TaÅŸkent': 'Konya', 'TuzlukÃ§u': 'Konya',
    'YalÄ±hÃ¼yÃ¼k': 'Konya', 'Yunak': 'Konya',
    
    # Gaziantep districts
    'Araban': 'Gaziantep', 'Ä°slahiye': 'Gaziantep', 'KarkamÄ±ÅŸ': 'Gaziantep', 'Nizip': 'Gaziantep',
    'NurdaÄŸÄ±': 'Gaziantep', 'OÄŸuzeli': 'Gaziantep', 'Åahinbey': 'Gaziantep', 'Åehitkamil': 'Gaziantep',
    'Yavuzeli': 'Gaziantep',
    
    # Adana districts
    'AladaÄŸ': 'Adana', 'Ceyhan': 'Adana', 'Ã‡ukurova': 'Adana', 'Feke': 'Adana', 'Ä°mamoÄŸlu': 'Adana',
    'KaraisalÄ±': 'Adana', 'KarataÅŸ': 'Adana', 'Kozan': 'Adana', 'PozantÄ±': 'Adana', 'Saimbeyli': 'Adana',
    'SarÄ±Ã§am': 'Adana', 'Seyhan': 'Adana', 'Tufanbeyli': 'Adana', 'YumurtalÄ±k': 'Adana', 'YÃ¼reÄŸir': 'Adana',
    
    # Kocaeli districts
    'BaÅŸiskele': 'Kocaeli', 'Ã‡ayÄ±rova': 'Kocaeli', 'DarÄ±ca': 'Kocaeli', 'Derince': 'Kocaeli', 'DilovasÄ±': 'Kocaeli',
    'Gebze': 'Kocaeli', 'GÃ¶lcÃ¼k': 'Kocaeli', 'Ä°zmit': 'Kocaeli', 'KandÄ±ra': 'Kocaeli', 'KaramÃ¼rsel': 'Kocaeli',
    'Kartepe': 'Kocaeli', 'KÃ¶rfez': 'Kocaeli',
    
    # Mersin districts
    'Akdeniz': 'Mersin', 'Anamur': 'Mersin', 'AydÄ±ncÄ±k': 'Mersin', 'BozyazÄ±': 'Mersin', 'Ã‡amlÄ±yayla': 'Mersin',
    'Erdemli': 'Mersin', 'GÃ¼lnar': 'Mersin', 'Mezitli': 'Mersin', 'Mut': 'Mersin', 'Silifke': 'Mersin',
    'Tarsus': 'Mersin', 'Toroslar': 'Mersin', 'YeniÅŸehir': 'Mersin',
    
    # DiyarbakÄ±r districts
    'BaÄŸlar': 'DiyarbakÄ±r', 'Bismil': 'DiyarbakÄ±r', 'Ã‡ermik': 'DiyarbakÄ±r', 'Ã‡Ä±nar': 'DiyarbakÄ±r', 'Ã‡Ã¼ngÃ¼ÅŸ': 'DiyarbakÄ±r',
    'Dicle': 'DiyarbakÄ±r', 'EÄŸil': 'DiyarbakÄ±r', 'Ergani': 'DiyarbakÄ±r', 'Hani': 'DiyarbakÄ±r', 'Hazro': 'DiyarbakÄ±r',
    'KayapÄ±nar': 'DiyarbakÄ±r', 'KocakÃ¶y': 'DiyarbakÄ±r', 'Kulp': 'DiyarbakÄ±r', 'Lice': 'DiyarbakÄ±r', 'Silvan': 'DiyarbakÄ±r',
    'Sur': 'DiyarbakÄ±r', 'YeniÅŸehir': 'DiyarbakÄ±r',
    
    # Hatay districts
    'AltÄ±nÃ¶zÃ¼': 'Hatay', 'Arsuz': 'Hatay', 'Belen': 'Hatay', 'Defne': 'Hatay', 'DÃ¶rtyol': 'Hatay',
    'Erzin': 'Hatay', 'Hassa': 'Hatay', 'Ä°skenderun': 'Hatay', 'KÄ±rÄ±khan': 'Hatay', 'Kumlu': 'Hatay',
    'Payas': 'Hatay', 'ReyhanlÄ±': 'Hatay', 'SamandaÄŸ': 'Hatay', 'YayladaÄŸÄ±': 'Hatay',
    
    # Manisa districts
    'Ahmetli': 'Manisa', 'Akhisar': 'Manisa', 'AlaÅŸehir': 'Manisa', 'Demirci': 'Manisa', 'GÃ¶lmarmara': 'Manisa',
    'GÃ¶rdes': 'Manisa', 'KÄ±rkaÄŸaÃ§': 'Manisa', 'KÃ¶prÃ¼baÅŸÄ±': 'Manisa', 'Kula': 'Manisa', 'Salihli': 'Manisa',
    'SarÄ±gÃ¶l': 'Manisa', 'SaruhanlÄ±': 'Manisa', 'Selendi': 'Manisa', 'Soma': 'Manisa', 'Åehzadeler': 'Manisa',
    'Turgutlu': 'Manisa', 'Yunusemre': 'Manisa',
    
    # Kayseri districts
    'AkkÄ±ÅŸla': 'Kayseri', 'BÃ¼nyan': 'Kayseri', 'Develi': 'Kayseri', 'Felahiye': 'Kayseri', 'HacÄ±lar': 'Kayseri',
    'Ä°ncesu': 'Kayseri', 'Kocasinan': 'Kayseri', 'Melikgazi': 'Kayseri', 'Ã–zvatan': 'Kayseri', 'PÄ±narbaÅŸÄ±': 'Kayseri',
    'SarÄ±oÄŸlan': 'Kayseri', 'SarÄ±z': 'Kayseri', 'Talas': 'Kayseri', 'Tomarza': 'Kayseri', 'YahyalÄ±': 'Kayseri',
    'YeÅŸilhisar': 'Kayseri',
    
    # Samsun districts
    '19 MayÄ±s': 'Samsun', 'AlaÃ§am': 'Samsun', 'AsarcÄ±k': 'Samsun', 'Atakum': 'Samsun', 'AyvacÄ±k': 'Samsun',
    'Bafra': 'Samsun', 'Canik': 'Samsun', 'Ã‡arÅŸamba': 'Samsun', 'Havza': 'Samsun', 'Ä°lkadÄ±m': 'Samsun',
    'Kavak': 'Samsun', 'Ladik': 'Samsun', 'OndokuzmayÄ±s': 'Samsun', 'SalÄ±pazarÄ±': 'Samsun', 'TekkekÃ¶y': 'Samsun',
    'Terme': 'Samsun', 'VezirkÃ¶prÃ¼': 'Samsun', 'Yakakent': 'Samsun',
    
    # BalÄ±kesir districts
    'AltÄ±eylÃ¼l': 'BalÄ±kesir', 'AyvalÄ±k': 'BalÄ±kesir', 'Balya': 'BalÄ±kesir', 'BandÄ±rma': 'BalÄ±kesir', 'BigadiÃ§': 'BalÄ±kesir',
    'Burhaniye': 'BalÄ±kesir', 'Dursunbey': 'BalÄ±kesir', 'Edremit': 'BalÄ±kesir', 'Erdek': 'BalÄ±kesir', 'GÃ¶meÃ§': 'BalÄ±kesir',
    'GÃ¶nen': 'BalÄ±kesir', 'Havran': 'BalÄ±kesir', 'Ä°vrindi': 'BalÄ±kesir', 'Karesi': 'BalÄ±kesir', 'Kepsut': 'BalÄ±kesir',
    'Manyas': 'BalÄ±kesir', 'Marmara': 'BalÄ±kesir', 'SavaÅŸtepe': 'BalÄ±kesir', 'SÄ±ndÄ±rgÄ±': 'BalÄ±kesir', 'Susurluk': 'BalÄ±kesir',
    
    # KahramanmaraÅŸ districts
    'AfÅŸin': 'KahramanmaraÅŸ', 'AndÄ±rÄ±n': 'KahramanmaraÅŸ', 'Ã‡aÄŸlayancerit': 'KahramanmaraÅŸ', 'DulkadiroÄŸlu': 'KahramanmaraÅŸ',
    'EkinÃ¶zÃ¼': 'KahramanmaraÅŸ', 'Elbistan': 'KahramanmaraÅŸ', 'GÃ¶ksun': 'KahramanmaraÅŸ', 'Nurhak': 'KahramanmaraÅŸ',
    'OnikiÅŸubat': 'KahramanmaraÅŸ', 'PazarcÄ±k': 'KahramanmaraÅŸ', 'TÃ¼rkoÄŸlu': 'KahramanmaraÅŸ',
    
    # Van districts
    'BahÃ§esaray': 'Van', 'BaÅŸkale': 'Van', 'Ã‡aldÄ±ran': 'Van', 'Ã‡atak': 'Van', 'Edremit': 'Van',
    'ErciÅŸ': 'Van', 'GevaÅŸ': 'Van', 'GÃ¼rpÄ±nar': 'Van', 'Ä°pekyolu': 'Van', 'TuÅŸba': 'Van', 'Muradiye': 'Van',
    'Ã–zalp': 'Van', 'Saray': 'Van',
    
    # Denizli districts
    'AcÄ±payam': 'Denizli', 'BabadaÄŸ': 'Denizli', 'Baklan': 'Denizli', 'Bekilli': 'Denizli', 'BeyaÄŸaÃ§': 'Denizli',
    'Bozkurt': 'Denizli', 'Buldan': 'Denizli', 'Ã‡al': 'Denizli', 'Ã‡ameli': 'Denizli', 'Ã‡ardak': 'Denizli',
    'Ã‡ivril': 'Denizli', 'GÃ¼ney': 'Denizli', 'Honaz': 'Denizli', 'Kale': 'Denizli', 'Merkezefendi': 'Denizli',
    'Pamukkale': 'Denizli', 'SaraykÃ¶y': 'Denizli', 'Serinhisar': 'Denizli', 'Tavas': 'Denizli',
    
    # Sakarya districts
    'AdapazarÄ±': 'Sakarya', 'AkyazÄ±': 'Sakarya', 'Arifiye': 'Sakarya', 'Erenler': 'Sakarya', 'Ferizli': 'Sakarya',
    'Geyve': 'Sakarya', 'Hendek': 'Sakarya', 'KarapÃ¼rÃ§ek': 'Sakarya', 'Karasu': 'Sakarya', 'Kaynarca': 'Sakarya',
    'Kocaali': 'Sakarya', 'Pamukova': 'Sakarya', 'Sapanca': 'Sakarya', 'Serdivan': 'Sakarya', 'SÃ¶ÄŸÃ¼tlÃ¼': 'Sakarya',
    'TaraklÄ±': 'Sakarya',
    
    # MuÄŸla districts
    'Bodrum': 'MuÄŸla', 'Dalaman': 'MuÄŸla', 'DatÃ§a': 'MuÄŸla', 'Fethiye': 'MuÄŸla', 'KavaklÄ±dere': 'MuÄŸla',
    'KÃ¶yceÄŸiz': 'MuÄŸla', 'Marmaris': 'MuÄŸla', 'MenteÅŸe': 'MuÄŸla', 'Milas': 'MuÄŸla', 'Ortaca': 'MuÄŸla',
    'Seydikemer': 'MuÄŸla', 'Ula': 'MuÄŸla', 'YataÄŸan': 'MuÄŸla',
    
    # EskiÅŸehir districts
    'Alpu': 'EskiÅŸehir', 'Beylikova': 'EskiÅŸehir', 'Ã‡ifteler': 'EskiÅŸehir', 'GÃ¼nyÃ¼zÃ¼': 'EskiÅŸehir', 'Han': 'EskiÅŸehir',
    'Ä°nÃ¶nÃ¼': 'EskiÅŸehir', 'Mahmudiye': 'EskiÅŸehir', 'Mihalgazi': 'EskiÅŸehir', 'MihalÄ±Ã§Ã§Ä±k': 'EskiÅŸehir', 'OdunpazarÄ±': 'EskiÅŸehir',
    'SarÄ±cakaya': 'EskiÅŸehir', 'Seyitgazi': 'EskiÅŸehir', 'Sivrihisar': 'EskiÅŸehir', 'TepebaÅŸÄ±': 'EskiÅŸehir',
    
    # Trabzon districts
    'AkÃ§aabat': 'Trabzon', 'AraklÄ±': 'Trabzon', 'Arsin': 'Trabzon', 'BeÅŸikdÃ¼zÃ¼': 'Trabzon', 'Ã‡arÅŸÄ±baÅŸÄ±': 'Trabzon',
    'Ã‡aykara': 'Trabzon', 'DernekpazarÄ±': 'Trabzon', 'DÃ¼zkÃ¶y': 'Trabzon', 'Hayrat': 'Trabzon', 'KÃ¶prÃ¼baÅŸÄ±': 'Trabzon',
    'MaÃ§ka': 'Trabzon', 'Of': 'Trabzon', 'Ortahisar': 'Trabzon', 'SÃ¼rmene': 'Trabzon', 'ÅalpazarÄ±': 'Trabzon',
    'Tonya': 'Trabzon', 'VakfÄ±kebir': 'Trabzon', 'Yomra': 'Trabzon',
    
    # Ordu districts
    'AkkuÅŸ': 'Ordu', 'AltÄ±nordu': 'Ordu', 'AybastÄ±': 'Ordu', 'Ã‡amaÅŸ': 'Ordu', 'Ã‡atalpÄ±nar': 'Ordu',
    'Ã‡aybaÅŸÄ±': 'Ordu', 'Fatsa': 'Ordu', 'GÃ¶lkÃ¶y': 'Ordu', 'GÃ¼lyalÄ±': 'Ordu', 'GÃ¼rgentepe': 'Ordu',
    'Ä°kizce': 'Ordu', 'KabadÃ¼z': 'Ordu', 'KabataÅŸ': 'Ordu', 'Korgan': 'Ordu', 'Kumru': 'Ordu',
    'Mesudiye': 'Ordu', 'PerÅŸembe': 'Ordu', 'Piraziz': 'Ordu', 'Ulubey': 'Ordu', 'Ãœnye': 'Ordu',
    
    # Malatya districts
    'AkÃ§adaÄŸ': 'Malatya', 'Arapgir': 'Malatya', 'Arguvan': 'Malatya', 'Battalgazi': 'Malatya', 'Darende': 'Malatya',
    'DoÄŸanÅŸehir': 'Malatya', 'DoÄŸanyol': 'Malatya', 'Hekimhan': 'Malatya', 'Kale': 'Malatya', 'Kuluncak': 'Malatya',
    'PÃ¼tÃ¼rge': 'Malatya', 'YazÄ±han': 'Malatya', 'YeÅŸilyurt': 'Malatya',
    
    # Erzurum districts
    'AÅŸkale': 'Erzurum', 'Aziziye': 'Erzurum', 'Ã‡at': 'Erzurum', 'HÄ±nÄ±s': 'Erzurum', 'Horasan': 'Erzurum',
    'Ä°spir': 'Erzurum', 'KaraÃ§oban': 'Erzurum', 'KarayazÄ±': 'Erzurum', 'KÃ¶prÃ¼kÃ¶y': 'Erzurum', 'Narman': 'Erzurum',
    'Oltu': 'Erzurum', 'Olur': 'Erzurum', 'PalandÃ¶ken': 'Erzurum', 'Pasinler': 'Erzurum', 'Pazaryolu': 'Erzurum',
    'Åenkaya': 'Erzurum', 'Tekman': 'Erzurum', 'Tortum': 'Erzurum', 'Uzundere': 'Erzurum', 'Yakutiye': 'Erzurum',
    
    # TekirdaÄŸ districts
    'Ã‡erkezkÃ¶y': 'TekirdaÄŸ', 'Ã‡orlu': 'TekirdaÄŸ', 'Ergene': 'TekirdaÄŸ', 'Hayrabolu': 'TekirdaÄŸ', 'KapaklÄ±': 'TekirdaÄŸ',
    'Malkara': 'TekirdaÄŸ', 'MarmaraereÄŸlisi': 'TekirdaÄŸ', 'MuratlÄ±': 'TekirdaÄŸ', 'Saray': 'TekirdaÄŸ', 'SÃ¼leymanpaÅŸa': 'TekirdaÄŸ',
    'ÅarkÃ¶y': 'TekirdaÄŸ',
    
    # Zonguldak districts
    'AlaplÄ±': 'Zonguldak', 'Ã‡aycuma': 'Zonguldak', 'Devrek': 'Zonguldak', 'GÃ¶kÃ§ebey': 'Zonguldak', 'Kilimli': 'Zonguldak',
    'Kozlu': 'Zonguldak', 'Merkez': 'Zonguldak',
    
    # Other major districts
}


# Create combined list of cities and districts for pattern matching
_all_locations = SEHIRLER + list(DISTRICT_TO_CITY.keys())
_sorted_locations = sorted(_all_locations, key=len, reverse=True)
_location_pattern = re.compile(r"\b(" + "|".join(map(re.escape, _sorted_locations)) + r")(?:'?[dDbB][ea]|'?[dDtT][an]|'?[yY][ae])?\b", re.IGNORECASE)


def detect_city_from_text(text: str) -> str | None:
    """
    Detects city from text by checking both official cities and districts.
    Returns the official city name (from SEHIRLER list) for display purposes.
    
    Args:
        text (str): Text to search for location
        
    Returns:
        str | None: Official city name or None if no location found
    """
    if not text:
        return None
    
    # Normalize text
    candidate = text.strip()
    m = _location_pattern.search(candidate)
    
    if m:
        found = m.group(1)
        
        # First check if it's a direct city match
        for city in SEHIRLER:
            if city.lower() == found.lower():
                return city
        
        # Then check if it's a district and return its parent city
        for district, parent_city in DISTRICT_TO_CITY.items():
            if district.lower() == found.lower():
                return parent_city
        
        # If no exact match found, return the found text (fallback)
        return found
    
    return None


def detect_location_details(text: str) -> dict | None:
    """
    Detects both city and district from text.
    Returns detailed location information including both city and district.
    
    Args:
        text (str): Text to search for location
        
    Returns:
        dict | None: Dictionary with 'city', 'district', and 'is_district' keys, or None if no location found
    """
    if not text:
        return None
    
    # Normalize text
    candidate = text.strip()
    m = _location_pattern.search(candidate)
    
    if m:
        found = m.group(1)
        
        # First check if it's a direct city match
        for city in SEHIRLER:
            if city.lower() == found.lower():
                return {
                    'city': city,  # Return the properly capitalized city name
                    'district': None,
                    'is_district': False,
                    'original_text': found
                }
        
        # Then check if it's a district and return its parent city
        for district, parent_city in DISTRICT_TO_CITY.items():
            if district.lower() == found.lower():
                return {
                    'city': parent_city,
                    'district': district,  # Return the properly capitalized district name
                    'is_district': True,
                    'original_text': found
                }
        
        # If no exact match found, return the found text as city (fallback)
        return {
            'city': found,
            'district': None,
            'is_district': False,
            'original_text': found
        }
    
    return None


def get_location_statistics(tweets: list) -> dict:
    """
    Analyzes location detection statistics from a list of tweets.
    
    Args:
        tweets (list): List of tweet dictionaries
        
    Returns:
        dict: Statistics about location detection
    """
    stats = {
        'total_tweets': len(tweets),
        'tweets_with_location': 0,
        'tweets_with_district': 0,
        'city_counts': {},
        'district_counts': {},
        'location_detection_rate': 0.0
    }
    
    for tweet in tweets:
        location_details = tweet.get('location_details')
        if location_details:
            stats['tweets_with_location'] += 1
            
            city = location_details.get('city')
            district = location_details.get('district')
            
            if city:
                stats['city_counts'][city] = stats['city_counts'].get(city, 0) + 1
            
            if district:
                stats['tweets_with_district'] += 1
                stats['district_counts'][district] = stats['district_counts'].get(district, 0) + 1
    
    if stats['total_tweets'] > 0:
        stats['location_detection_rate'] = (stats['tweets_with_location'] / stats['total_tweets']) * 100
    
    return stats


class SeleniumTwitterScraper:
    def __init__(self, headless=True):
        """
        selenium twitter scraper 
        """
       
        self.headless = headless
        self.driver = None
        self.wait = None
        self.is_logged_in = False
        
        # manuel twitter giriÅŸi yapÄ±lÄ±yor
        
      
        self.disaster_keywords = [
            # trafik / ulaÅŸÄ±m
            "trafik", "yoÄŸunluk", "kilit", "E-5", "D-100",
            "metrobÃ¼s", "metro arÄ±zasÄ±", "otobÃ¼s gecikme", "sefer iptal", "aktarma",

            # yaÄŸÄ±ÅŸ / sel
            "yaÄŸmur", "saÄŸanak", "dolu", "fÄ±rtÄ±na", "ÅŸiddetli yaÄŸÄ±ÅŸ",
            "sel", "su baskÄ±nÄ±", "dere taÅŸtÄ±", "mazgal", "altgeÃ§it su",

            # enerji / elektrik
            "enerji kesintisi", "trafo", "hat arÄ±zasÄ±", "yÃ¼ksek tÃ¼ketim", "elektrik",
            "elektrik kesildi", "elektrik yok", "elektrikler gitti", "arÄ±za bildirimi", "kesinti programÄ±",

            # atÄ±k / Ã§evre kirliliÄŸi
            "Ã§Ã¶p birikmiÅŸ", "Ã§Ã¶p toplanmÄ±yor", "koku var", "dÃ¶kÃ¼ntÃ¼", "Ã§Ã¶p konteyneri",
            "kirlilik", "duman", "is kokusu", "zehirli", "sanayi atÄ±ÄŸÄ±",

            # yardÄ±m
            "yardÄ±m lazÄ±m", "gÃ¶nÃ¼llÃ¼", "ihtiyaÃ§ var", "baÄŸÄ±ÅŸ", "destek",

            # afetler
            "deprem", "artÃ§Ä±", "AFAD", "sarsÄ±ntÄ±", "fay",
            "yangÄ±n", "itfaiye", "duman yÃ¼kseliyor", "orman yangÄ±nÄ±", "baca",

            # gÃ¼rÃ¼ltÃ¼
            "gÃ¼rÃ¼ltÃ¼", "yÃ¼ksek ses", "inÅŸaat sesi", "gece gÃ¼rÃ¼ltÃ¼", "rahatsÄ±z",

            # kamusal alan / yeÅŸil alan
            "park bakÄ±msÄ±z", "kaldÄ±rÄ±m bozuk", "bank kÄ±rÄ±k", "oyun alanÄ±", "kamusal alan",
            "aÄŸaÃ§ kesimi", "yeÅŸil alan", "koru", "millet bahÃ§esi",

            # su / barÄ±nma
            "su kesildi", "sular yok", "baraj seviyesi", "isale hattÄ±", "ÅŸebeke suyu",
            "barÄ±nma", "Ã§adÄ±r", "kira Ã§ok yÃ¼ksek", "yurt yok", "sokakta kaldÄ±k",

            # saÄŸlÄ±k / eÄŸitim
            "ambulans", "acil servis", "hastane yoÄŸunluk", "eczane nÃ¶bet", "saÄŸlÄ±k hizmeti",
            "okul kapalÄ±", "okul servisi", "uzaktan eÄŸitim", "tatil edildi", "sÄ±nav ertelendi",
    
        ]
        
      
        self.disaster_hashtags = [
            '#deprem', '#yangÄ±n', '#afet',

        ]
        
        
        self.tweets = []
        self.is_running = False
        
      
        
    def setup_driver(self):
        """chrome driver'Ä± kurar """
        try:
            
            options = Options()
            if self.headless:
                options.add_argument('--headless')
            options.add_argument('--no-sandbox')
            options.add_argument('--disable-dev-shm-usage')
            options.add_argument('--disable-blink-features=AutomationControlled')
            options.add_experimental_option("excludeSwitches", ["enable-automation"])
            options.add_experimental_option('useAutomationExtension', False)
            
            
            ua = UserAgent()
            options.add_argument(f'--user-agent={ua.random}')
            
            # driver kur
            service = Service(ChromeDriverManager().install())
            self.driver = webdriver.Chrome(service=service, options=options)
            self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            self.wait = WebDriverWait(self.driver, 10)
            print("*** chrome driver baÅŸarÄ±yla kuruldu")
            return True
            
        except Exception as e:
            print(f":(((((( driver kurulum hatasÄ±: {e}")
            return False
    
    def login_to_twitter(self):
        """twitter'a manuel giriÅŸ"""
        if not self.driver:
            if not self.setup_driver():
                return False
        
        try:
            print("--- twitter giriÅŸ sayfasÄ± aÃ§Ä±lÄ±yor...")
            print("+++ giriÅŸ yaptÄ±ktan sonra bu terminal'e dÃ¶nÃ¼n ve enter'a basÄ±n")
            
            # twitter giriÅŸ sayfasÄ±na git
            self.driver.get("https://twitter.com/login")
            
            # manuel giriÅŸ iÃ§in bekle
            input("+++ giriÅŸ yaptÄ±ktan sonra enter'a bas")
            
            # giriÅŸ baÅŸarÄ±lÄ± mÄ± kontrol et
            print("--- giriÅŸ durumu kontrol ediliyor")
            
            # ana sayfaya git
            self.driver.get("https://twitter.com/home")
            time.sleep(3)
            
            if "home" in self.driver.current_url:
                print("--- twitter'a baÅŸarÄ±yla giriÅŸ yapÄ±ldÄ±!")
                self.is_logged_in = True
                return True
            else:
                print("--- giriÅŸ durumu belirsiz, devam ediliyor")
                self.is_logged_in = True  # manuel giriÅŸ yapÄ±ldÄ±ÄŸÄ± varsayÄ±lÄ±yor
                return True
                    
        except Exception as e:
            print(f"--- giriÅŸ hatasÄ±: {e}")
            return False
    
    def search_twitter(self, query, max_tweets=50, scroll_count=5):
        """
        twitter'da arama yapar
        
        Args:
            query (str): arama sorgusu
            max_tweets (int): maksimum tweet sayÄ±sÄ±
            scroll_count (int): sayfa kaydÄ±rma sayÄ±sÄ±
        """
        if not self.driver:
            if not self.setup_driver():
                return []
        
    
        if not self.is_logged_in:
            if not self.login_to_twitter():
                print("--- twitter'a giriÅŸ yapÄ±lamadÄ±!")
                return []
        
        try:
            search_url = f"https://twitter.com/search?q={query}&src=typed_query&f=live"
            print(f"--- twitter'da aranÄ±yor: {query}")
            print(f"--- url: {search_url}")
            
            self.driver.get(search_url)
            time.sleep(5) 
            
            # tweet'leri topla
            tweets = []
            last_height = self.driver.execute_script("return document.body.scrollHeight")
            
            for scroll in range(scroll_count):
                print(f"--- sayfa {scroll + 1}/{scroll_count} kaydÄ±rÄ±lÄ±yor")
                
                
                tweet_selectors = [
                    '[data-testid="tweet"]',
                    'article[data-testid="tweet"]',
                    'div[data-testid="tweetText"]',
                    'div[lang]'
                ]
                
                tweet_elements = []
                for selector in tweet_selectors:
                    try:
                        elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                        if elements:
                            tweet_elements = elements
                            print(f"âœ… Tweet selector bulundu: {selector}")
                            break
                    except:
                        continue
                
                if not tweet_elements:
                    print("âš ï¸ Tweet elementleri bulunamadÄ±, sayfa yapÄ±sÄ± kontrol ediliyor...")
                    page_source = self.driver.page_source
                    if "tweet" in page_source.lower():
                        print("ğŸ“„ Sayfada tweet iÃ§eriÄŸi var ama selector bulunamadÄ±")
                    else:
                        print("ğŸ“„ Sayfa boÅŸ gÃ¶rÃ¼nÃ¼yor")
                
                for tweet_element in tweet_elements:
                    if len(tweets) >= max_tweets:
                        break
                    
                    try:
                        tweet_data = self._extract_tweet_data(tweet_element, query)
                        if tweet_data and tweet_data not in tweets:
                            tweets.append(tweet_data)
                            print(f"ğŸ“ Tweet Ã§ekildi: {tweet_data['text'][:50]}...")
                    except Exception as e:
                        print(f"âš ï¸ Tweet Ã§Ä±karma hatasÄ±: {e}")
                        continue
                
                # sayfayÄ± aÅŸaÄŸÄ± kaydÄ±r
                self.driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # yeni iÃ§erik yÃ¼klendi mi kontrol et
                new_height = self.driver.execute_script("return document.body.scrollHeight")
                if new_height == last_height:
                    print("--- sayfa sonuna ulaÅŸÄ±ldÄ±")
                    break
                last_height = new_height
                
                # rate limiting iÃ§in bekle
                time.sleep(random.uniform(2, 4))
            
            print(f"--- toplam {len(tweets)} tweet Ã§ekildi")
            return tweets
            
        except Exception as e:
            print(f"--- arama hatasÄ±: {e}")
            return []
    
    def _extract_tweet_data(self, tweet_element, search_query):
        """tweet elementinden veri Ã§Ä±karÄ±r"""
        try:
            # farklÄ± tweet metni selector'larÄ±nÄ± dene
            text_selectors = [
                '[data-testid="tweetText"]',
                'div[lang]',
                'div[dir="ltr"]',
                'span'
            ]
            
            text = ""
            for selector in text_selectors:
                try:
                    text_element = tweet_element.find_element(By.CSS_SELECTOR, selector)
                    if text_element and text_element.text.strip():
                        text = text_element.text.strip()
                        break
                except:
                    continue
            
            # kullanÄ±cÄ± adÄ± ve profil URL'si
            username = "unknown"
            profile_url = None
            try:
                # kullanÄ±cÄ± adÄ± genelde kartta ilk linklerden biri, /status/ iÃ§ermeyen kullanÄ±cÄ± profiline gider
                links = tweet_element.find_elements(By.CSS_SELECTOR, 'a[role="link"]')
                for a in links:
                    href = a.get_attribute('href')
                    if href and re.match(r'^https?://(www\.)?twitter\.com/[^/]+/?$', href):
                        profile_url = href
                        # link text'lerinden kullanÄ±cÄ± adÄ±nÄ± almayÄ± dene
                        if a.text and a.text.strip():
                            username = a.text.strip()
                        break
            except:
                pass
            
            # tweet zamanÄ± (adventure time reference
            time_element = None
            try:
                time_element = tweet_element.find_element(By.CSS_SELECTOR, 'time')
            except:
                pass
            tweet_time = time_element.get_attribute('datetime') if time_element else datetime.now().isoformat()
            
            # tweet ID (URL'den Ã§Ä±kar)
            tweet_id = None
            try:
                tweet_link = tweet_element.find_element(By.CSS_SELECTOR, 'a[href*="/status/"]')
                href = tweet_link.get_attribute('href')
                if href:
                    tweet_id = href.split('/')[-1]
            except:
                pass
            
            # tweet'e ekli yer
            tweet_place = None
            try:
                place_link = tweet_element.find_element(By.CSS_SELECTOR, 'a[href^="/place/"]')
                if place_link and place_link.text.strip():
                    tweet_place = place_link.text.strip()
            except:
                try:
                    place_span = tweet_element.find_element(By.XPATH, ".//span[contains(@aria-label, 'Konum') or contains(@aria-label, 'Location')]")
                    if place_span and place_span.text.strip():
                        tweet_place = place_span.text.strip()
                except:
                    pass
            
            # afet ile ilgili mi kontrol et
            is_disaster_related = self._is_disaster_related(text)
            
            # metinden ÅŸehir ve ilÃ§e Ã§Ä±karÄ±mÄ±
            location_details = detect_location_details(text)
            location = location_details['city'] if location_details else None
            
            tweet_data = {
                'id': tweet_id,
                'text': text,
                'username': username,
                'created_at': tweet_time,
                'search_query': search_query,
                'disaster_related': is_disaster_related,
                'location': location,  # Official city name for backward compatibility
                'location_details': location_details,  # Detailed location info including district
                'scraping_method': 'twitter_scrape',
                'scraping_timestamp': datetime.now() #isoformat() da olabilir
            }
            
            return tweet_data
            
        except Exception as e:
            print(f"--- tweet veri Ã§Ä±karma hatasÄ±: {e}")
            return None
    
    def _is_disaster_related(self, text):
        """tweet metninin afet ile ilgili olup olmadÄ±ÄŸÄ±nÄ± kontrol eder"""
        if not text:
            return False
        
        text_lower = text.lower()
        
        # anahtar kelime kontrolÃ¼
        for keyword in self.disaster_keywords:
            if keyword in text_lower:
                return True
        
        # hashtag kontrolÃ¼
        for hashtag in self.disaster_hashtags:
            if hashtag.lower() in text_lower:
                return True
        
        # acil durum kelimeleri lazÄ±m olur belki
        emergency_words = ['acil', 'kaza', 'felaket', 'emergency', 'accident', 'disaster']
        for word in emergency_words:
            if word in text_lower:
                return True
        
        return False
    
    def live_monitoring_mode(self, keywords=None, interval_seconds=30, max_tweets_per_search=20):
        """
        canlÄ± izleme modu - belirli aralÄ±klarla arama yapar
        """
        if not keywords:
            keywords = self.disaster_keywords[:5] 
        
        print(f"--- canlÄ± izleme modu baÅŸlatÄ±lÄ±yor!")
        print(f"--- izlenen anahtar kelimeler: {', '.join(keywords)}")
        print(f"--- arama aralÄ±ÄŸÄ±: {interval_seconds} saniye")
        print(f"--- her aramada tweet: {max_tweets_per_search}")
        print("--" * 60)
        
        self.is_running = True
        search_count = 0
        total_tweets = 0
        disaster_tweets = 0
        
        try:
            while self.is_running:
                search_count += 1
                current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                
                print(f"\nğŸ• {current_time} - Arama #{search_count}")
                
                # anahtar kelimeleri sÄ±rayla ara
                keyword_index = (search_count - 1) % len(keywords)
                keyword = keywords[keyword_index]
                
                try:
                    tweets = self.search_twitter(
                        query=keyword,
                        max_tweets=max_tweets_per_search,
                        scroll_count=3
                    )
                    
                    if tweets:
                        # yeni tweet'leri kaydet
                        self.tweets.extend(tweets)
                        total_tweets += len(tweets)
                        
                        # afet tweet'lerini kontrol et
                        new_disaster_tweets = [t for t in tweets if t.get('disaster_related', False)]
                        disaster_tweets += len(new_disaster_tweets)
                        
                        if new_disaster_tweets:
                            print(f"ğŸš¨ {len(new_disaster_tweets)} afet tweet'i tespit edildi!")
                            for tweet in new_disaster_tweets[:3]:
                                print(f"  ğŸš¨ @{tweet['username']}: {tweet['text'][:80]}...")
                            
                            # Acil durum bildirimi
                            self._save_emergency_tweets(new_disaster_tweets)
                        
                        # istatistikleri gÃ¶ster
                        print(f"--- Ã¶zet: {total_tweets} tweet, {disaster_tweets} afet tweet")
                    
                    # batch kaydetme
                    if search_count % 5 == 0:
                        self._save_tweets_batch()
                    
                except Exception as e:
                    print(f"--- {keyword} aramasÄ±nda hata: {e}")
                    continue
                
                print(f"--- {interval_seconds} saniye bekleniyor... (durdurmak iÃ§in Ctrl+C)")
                time.sleep(interval_seconds)
                
        except KeyboardInterrupt:
            print(f"\n--- canlÄ± izleme durduruldu!")
            print(f"--- toplam: {search_count} arama, {total_tweets} tweet, {disaster_tweets} afet tweet")
            self._save_tweets_batch()
        except Exception as e:
            print(f"--- canlÄ± izleme hatasÄ±: {e}")
        finally:
            self.is_running = False
    
    def _save_emergency_tweets(self, emergency_tweets):
        """acil durum tweet'lerini ayrÄ± dosyaya kaydeder lazÄ±m olur belki"""
        try:
            # twitter_data klasÃ¶rÃ¼nÃ¼ oluÅŸtur
            os.makedirs("twitter_data", exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"twitter_data/emergency_tweets_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(emergency_tweets, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"--- acil durum tweet'leri kaydedildi: {filename}")
            
        except Exception as e:
            print(f"--- acil durum kaydetme hatasÄ±: {e}")
    
    def _save_tweets_batch(self):
        """tweet batch'ini dosyaya kaydeder"""
        try:
            if not self.tweets:
                return
            
            # twitter_data klasÃ¶rÃ¼nÃ¼ oluÅŸtur
            os.makedirs("twitter_data", exist_ok=True)
            
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"twitter_data/selenium_tweets_batch_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(self.tweets, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"ğŸ’¾ {len(self.tweets)} tweet {filename} dosyasÄ±na kaydedildi")
            
            # belleÄŸi temizle
            self.tweets = []
            
        except Exception as e:
            print(f"--- batch kaydetme hatasÄ±: {e}")
    
    def search_disaster_tweets(self, keyword="deprem", count=50):
        """belirli bir afet anahtar kelimesi iÃ§in tweet'leri arar"""
        return self.search_twitter(query=keyword, max_tweets=count)
    
    def search_multiple_keywords(self, keywords, tweets_per_keyword=20):
        """birden fazla anahtar kelime iÃ§in arama yapar"""
        all_tweets = []
        
        for keyword in keywords:
            print(f"ğŸ” {keyword} aranÄ±yor...")
            tweets = self.search_twitter(query=keyword, max_tweets=tweets_per_keyword)
            all_tweets.extend(tweets)
            
            # rate limiting iÃ§in bekle
            time.sleep(random.uniform(2, 5))
        
        return all_tweets
    
    def close(self):
        """driver'Ä± kapatÄ±r"""
        if self.driver:
            self.driver.quit()
            print("--- driver kapatÄ±ldÄ±")

def main():
    """ana fonksiyon"""
    print("--- selenium tabanlÄ± twitter afet scraper")
    print("--" * 50)
    
    try:
        # scraper'Ä± baÅŸlat
        scraper = SeleniumTwitterScraper(headless=False)
        
        print("--- mod seÃ§in:")
        print("1. tek arama")
        print("2. Ã§oklu anahtar kelime arama")
        print("3. canlÄ± izleme modu")
        print("4. twitter'a giriÅŸ yap")
        
        choice = input("\nseÃ§iminiz (1-5): ").strip()
        
        if choice == "1":
            keyword = input("arama anahtar kelimesi (varsayÄ±lan: deprem): ").strip() or "deprem"
            count = input("tweet sayÄ±sÄ± (varsayÄ±lan: 50): ").strip()
            count = int(count) if count.isdigit() else 50
            
            tweets = scraper.search_disaster_tweets(keyword, count)
            
        elif choice == "2":
            keywords_input = input("Anahtar kelimeler (virgÃ¼lle ayÄ±rÄ±n): ").strip()
            keywords = [k.strip() for k in keywords_input.split(',')] if keywords_input else ['deprem', 'sel', 'yangÄ±n']
            tweets_per_keyword = input("Her anahtar kelime iÃ§in tweet sayÄ±sÄ± (varsayÄ±lan: 20): ").strip()
            tweets_per_keyword = int(tweets_per_keyword) if tweets_per_keyword.isdigit() else 20
            
            tweets = scraper.search_multiple_keywords(keywords, tweets_per_keyword)
            
        elif choice == "3":
            print("--- canlÄ± izleme modu seÃ§ildi!")
            keywords_input = input("izlenecek anahtar kelimeler (virgÃ¼lle ayÄ±rÄ±n, boÅŸ=varsayÄ±lan): ").strip()
            keywords = [k.strip() for k in keywords_input.split(',')] if keywords_input else None
            
            interval = input("arama aralÄ±ÄŸÄ± (saniye, varsayÄ±lan: 30): ").strip()
            interval = int(interval) if interval.isdigit() else 30
            
            max_tweets = input("her aramada tweet sayÄ±sÄ± (varsayÄ±lan: 20): ").strip()
            max_tweets = int(max_tweets) if max_tweets.isdigit() else 20
            
            scraper.live_monitoring_mode(keywords, interval, max_tweets)
            return
            
        elif choice == "4":
            print("--- twitter'a giriÅŸ yapÄ±lÄ±yor...")
            if scraper.login_to_twitter():
                print("--- giriÅŸ baÅŸarÄ±lÄ±! ÅŸimdi arama yapabilirsiniz.")
            else:
                print("--- giriÅŸ baÅŸarÄ±sÄ±z!")
            return
            
        else:
            print("--- geÃ§ersiz seÃ§im, varsayÄ±lan olarak deprem aramasÄ± yapÄ±lacak")
            tweets = scraper.search_disaster_tweets("deprem", 50)
        
        if tweets:
            # tweet'leri kaydet
            os.makedirs("twitter_data", exist_ok=True)
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"twitter_data/selenium_tweets_{timestamp}.json"
            
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(tweets, f, ensure_ascii=False, indent=2, default=str)
            
            print(f"\n--- Ã¶zet:")
            print(f"  â€¢ toplam tweet: {len(tweets)}")
            print(f"  â€¢ kayÄ±t dosyasÄ±: {filename}") 
            
            disaster_count = sum(1 for tweet in tweets if tweet.get('disaster_related', False))
            print(f"  â€¢ afet ile ilgili tweet: {disaster_count}")
            
            # Location statistics
            location_stats = get_location_statistics(tweets)
            print(f"  â€¢ konum tespit edilen tweet: {location_stats['tweets_with_location']} ({location_stats['location_detection_rate']:.1f}%)")
            print(f"  â€¢ ilÃ§e tespit edilen tweet: {location_stats['tweets_with_district']}")
            
            if location_stats['city_counts']:
                top_cities = sorted(location_stats['city_counts'].items(), key=lambda x: x[1], reverse=True)[:5]
                print(f"  â€¢ en Ã§ok geÃ§en ÅŸehirler: {', '.join([f'{city}({count})' for city, count in top_cities])}")
            
            if location_stats['district_counts']:
                top_districts = sorted(location_stats['district_counts'].items(), key=lambda x: x[1], reverse=True)[:3]
                print(f"  â€¢ en Ã§ok geÃ§en ilÃ§eler: {', '.join([f'{district}({count})' for district, count in top_districts])}")
            
          
        
    except Exception as e:
        print(f"--- hata oluÅŸtu: {e}")
    finally:
        # driver'Ä± kapat
        if 'scraper' in locals():
            scraper.close()

if __name__ == "__main__":
    main()



